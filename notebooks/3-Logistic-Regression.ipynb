{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "* Flux can be used create a simple logistic regression model.\n",
    "* This can be seen as one node in a neural network - an affine transformation + an activation function (softmax).\n",
    "* Here we'll start using more of the typical Deep Learning tools: `Dense`, `Chain`, `softmax`, `train`, `crossentropy` and an `SGD` optimizer.\n",
    "* We'll also do some basic data prep on the iris data, in particular:\n",
    "    * Normalize it to have mean of 0 and standard deviation of 1.\n",
    "    * Split it into training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, Plots\n",
    "using MLBase: labelmap, labelencode\n",
    "using MLDataUtils: shuffleobs, splitobs\n",
    "using Statistics: mean, std\n",
    "\n",
    "using Flux, Flux.Tracker\n",
    "using Flux: onehotbatch, onecold, crossentropy, data, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd(@__DIR__)\n",
    "\n",
    "# Download the iris data set if it is not already pressent.\n",
    "isfile(\"iris.data\") ||\n",
    "    download(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", \n",
    "    \"iris.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sepal_length</th><th>sepal_width</th><th>petal_length</th><th>petal_width</th><th>species</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>String</th></tr></thead><tbody><p>5 rows × 5 columns</p><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>4</th><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>5</th><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& sepal\\_length & sepal\\_width & petal\\_length & petal\\_width & species\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & Iris-setosa \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & Iris-setosa \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & Iris-setosa \\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & Iris-setosa \\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & Iris-setosa \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×5 DataFrame\n",
       "│ Row │ sepal_length │ sepal_width │ petal_length │ petal_width │ species     │\n",
       "│     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mString\u001b[39m      │\n",
       "├─────┼──────────────┼─────────────┼──────────────┼─────────────┼─────────────┤\n",
       "│ 1   │ 5.1          │ 3.5         │ 1.4          │ 0.2         │ Iris-setosa │\n",
       "│ 2   │ 4.9          │ 3.0         │ 1.4          │ 0.2         │ Iris-setosa │\n",
       "│ 3   │ 4.7          │ 3.2         │ 1.3          │ 0.2         │ Iris-setosa │\n",
       "│ 4   │ 4.6          │ 3.1         │ 1.5          │ 0.2         │ Iris-setosa │\n",
       "│ 5   │ 5.0          │ 3.6         │ 1.4          │ 0.2         │ Iris-setosa │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset into a dataframe.  \n",
    "# None of the values are misssing, so force the datatypes of each rows to be \n",
    "# just Float64 or String with disallowmissing!.  Otherwise datatypes would be\n",
    "# Union{Float64,Missing}\n",
    "\n",
    "header = [\n",
    "    :sepal_length,\n",
    "    :sepal_width,\n",
    "    :petal_length,\n",
    "    :petal_width,\n",
    "    :species\n",
    "]\n",
    "\n",
    "iris = CSV.read(\"iris.data\", header=header, limit=150)\n",
    "\n",
    "disallowmissing!(iris)\n",
    "\n",
    "iris[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sepal_length</th><th>sepal_width</th><th>petal_length</th><th>petal_width</th><th>species</th><th>labels</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>String</th><th>Int64</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td><td>1</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td><td>1</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>Iris-setosa</td><td>1</td></tr><tr><th>4</th><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>Iris-setosa</td><td>1</td></tr><tr><th>5</th><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& sepal\\_length & sepal\\_width & petal\\_length & petal\\_width & species & labels\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & Iris-setosa & 1 \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & Iris-setosa & 1 \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & Iris-setosa & 1 \\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & Iris-setosa & 1 \\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & Iris-setosa & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ sepal_length │ sepal_width │ petal_length │ petal_width │ species     │\n",
       "│     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mString\u001b[39m      │\n",
       "├─────┼──────────────┼─────────────┼──────────────┼─────────────┼─────────────┤\n",
       "│ 1   │ 5.1          │ 3.5         │ 1.4          │ 0.2         │ Iris-setosa │\n",
       "│ 2   │ 4.9          │ 3.0         │ 1.4          │ 0.2         │ Iris-setosa │\n",
       "│ 3   │ 4.7          │ 3.2         │ 1.3          │ 0.2         │ Iris-setosa │\n",
       "│ 4   │ 4.6          │ 3.1         │ 1.5          │ 0.2         │ Iris-setosa │\n",
       "│ 5   │ 5.0          │ 3.6         │ 1.4          │ 0.2         │ Iris-setosa │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the species as an integer, call the new column 'labels'.\n",
    "\n",
    "# https://mlbasejl.readthedocs.io/en/latest/datapre.html#data-repetition\n",
    "lm = labelmap(iris[:species])\n",
    "\n",
    "iris[:labels] = labelencode(lm, iris[:species])\n",
    "\n",
    "iris[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 4 cols into a matrix of floats.\n",
    "# Matrix is just an alias for a 2d array, i.e. Array{Float32,2}\n",
    "X_raw = Matrix{Float32}(iris[1:end, 1:4])'\n",
    "\n",
    "# Extract the labels column as an array of 1-byte integers.\n",
    "y_raw = Array{Int8}(iris[:labels]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Array{Float32,2}:\n",
       " 5.84333  0.828066\n",
       " 3.054    0.433594\n",
       " 3.75867  1.76442 \n",
       " 1.19867  0.763161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The means and standard deviations of the raw feature matrix.\n",
    "# Want them to be 0 and 1, respectively.\n",
    "hcat(mean(X_raw, dims=2), std(X_raw,  dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Array{Float32,2}:\n",
       " -1.74463e-6  1.0\n",
       "  2.57939e-7  1.0\n",
       "  3.69549e-8  1.0\n",
       " -5.0505e-7   1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normlize.\n",
    "X_raw_normed = (X_raw .- mean(X_raw, dims = 2)) ./ std(X_raw, dims = 2)\n",
    "\n",
    "# Now can see that means are about 0 and stds are 1.\n",
    "hcat(mean(X_raw_normed, dims=2), std(X_raw_normed,  dims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Int8,1}:\n",
       " 2\n",
       " 3\n",
       " 1\n",
       " 2\n",
       " 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mix up the order of the examples, or 'observations'.\n",
    "Xs, ys = shuffleobs((X_raw_normed, y_raw))\n",
    "\n",
    "# 3 different species.  Remember that Julia has 1-based indexing\n",
    "ys[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(X_train) = (4, 100)\n",
      "size(X_test) = (4, 50)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test partions.\n",
    "# Use 2/3 for training.\n",
    "(X_train, y_train), (X_test, y_test) = splitobs((Xs, ys); at=0.67)\n",
    "\n",
    "@show size(X_train)\n",
    "@show size(X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×50 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " false  false   true   true  false  …   true  false   true  false   true\n",
       "  true   true  false  false  false     false  false  false   true  false\n",
       " false  false  false  false   true     false   true  false  false  false"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the labels.  Probably should have done this before splitting\n",
    "# the observations, but should still work.\n",
    "y_train_onehot = onehotbatch(y_train, levels(y_train))\n",
    "y_test_onehot  = onehotbatch(y_test,  levels(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "Chain(layers...)\n",
       "\\end{verbatim}\n",
       "Chain multiple layers / functions together, so that they are called in sequence on a given input.\n",
       "\n",
       "\\begin{verbatim}\n",
       "m = Chain(x -> x^2, x -> x+1)\n",
       "m(5) == 26\n",
       "\n",
       "m = Chain(Dense(10, 5), Dense(5, 2))\n",
       "x = rand(10)\n",
       "m(x) == m[2](m[1](x))\n",
       "\\end{verbatim}\n",
       "\\texttt{Chain} also supports indexing and slicing, e.g. \\texttt{m[2]} or \\texttt{m[1:end-1]}. \\texttt{m[1:3](x)} will calculate the output of the first three layers.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "Chain(layers...)\n",
       "```\n",
       "\n",
       "Chain multiple layers / functions together, so that they are called in sequence on a given input.\n",
       "\n",
       "```julia\n",
       "m = Chain(x -> x^2, x -> x+1)\n",
       "m(5) == 26\n",
       "\n",
       "m = Chain(Dense(10, 5), Dense(5, 2))\n",
       "x = rand(10)\n",
       "m(x) == m[2](m[1](x))\n",
       "```\n",
       "\n",
       "`Chain` also supports indexing and slicing, e.g. `m[2]` or `m[1:end-1]`. `m[1:3](x)` will calculate the output of the first three layers.\n"
      ],
      "text/plain": [
       "\u001b[36m  Chain(layers...)\u001b[39m\n",
       "\n",
       "  Chain multiple layers / functions together, so that they are called in\n",
       "  sequence on a given input.\n",
       "\n",
       "\u001b[36m  m = Chain(x -> x^2, x -> x+1)\u001b[39m\n",
       "\u001b[36m  m(5) == 26\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  m = Chain(Dense(10, 5), Dense(5, 2))\u001b[39m\n",
       "\u001b[36m  x = rand(10)\u001b[39m\n",
       "\u001b[36m  m(x) == m[2](m[1](x))\u001b[39m\n",
       "\n",
       "  \u001b[36mChain\u001b[39m also supports indexing and slicing, e.g. \u001b[36mm[2]\u001b[39m or \u001b[36mm[1:end-1]\u001b[39m. \u001b[36mm[1:3](x)\u001b[39m\n",
       "  will calculate the output of the first three layers."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22m \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mArray \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mVector \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mMatrix \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22mVecOrMat \u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22mity \u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22mity!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "Dense(in::Integer, out::Integer, σ = identity)\n",
       "\\end{verbatim}\n",
       "Creates a traditional \\texttt{Dense} layer with parameters \\texttt{W} and \\texttt{b}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "y = σ.(W * x .+ b)\n",
       "\\end{verbatim}\n",
       "The input \\texttt{x} must be a vector of length \\texttt{in}, or a batch of vectors represented as an \\texttt{in × N} matrix. The out \\texttt{y} will be a vector or batch of length \\texttt{out}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> d = Dense(5, 2)\n",
       "Dense(5, 2)\n",
       "\n",
       "julia> d(rand(5))\n",
       "Tracked 2-element Array{Float64,1}:\n",
       "  0.00257447\n",
       "  -0.00449443\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "Dense(in::Integer, out::Integer, σ = identity)\n",
       "```\n",
       "\n",
       "Creates a traditional `Dense` layer with parameters `W` and `b`.\n",
       "\n",
       "```\n",
       "y = σ.(W * x .+ b)\n",
       "```\n",
       "\n",
       "The input `x` must be a vector of length `in`, or a batch of vectors represented as an `in × N` matrix. The out `y` will be a vector or batch of length `out`.\n",
       "\n",
       "```julia\n",
       "julia> d = Dense(5, 2)\n",
       "Dense(5, 2)\n",
       "\n",
       "julia> d(rand(5))\n",
       "Tracked 2-element Array{Float64,1}:\n",
       "  0.00257447\n",
       "  -0.00449443\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  Dense(in::Integer, out::Integer, σ = identity)\u001b[39m\n",
       "\n",
       "  Creates a traditional \u001b[36mDense\u001b[39m layer with parameters \u001b[36mW\u001b[39m and \u001b[36mb\u001b[39m.\n",
       "\n",
       "\u001b[36m  y = σ.(W * x .+ b)\u001b[39m\n",
       "\n",
       "  The input \u001b[36mx\u001b[39m must be a vector of length \u001b[36min\u001b[39m, or a batch of vectors represented\n",
       "  as an \u001b[36min × N\u001b[39m matrix. The out \u001b[36my\u001b[39m will be a vector or batch of length \u001b[36mout\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> d = Dense(5, 2)\u001b[39m\n",
       "\u001b[36m  Dense(5, 2)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> d(rand(5))\u001b[39m\n",
       "\u001b[36m  Tracked 2-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.00257447\u001b[39m\n",
       "\u001b[36m    -0.00449443\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m log\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mx\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "softmax(xs) = exp.(xs) ./ sum(exp.(xs))\n",
       "\\end{verbatim}\n",
       "\\href{https://en.wikipedia.org/wiki/Softmax_function}{Softmax} takes log-probabilities (any real vector) and returns a probability distribution that sums to 1.\n",
       "\n",
       "If given a matrix it will treat it as a batch of vectors, with each column independent.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> softmax([1,2,3.])\n",
       "3-element Array{Float64,1}:\n",
       "  0.0900306\n",
       "  0.244728\n",
       "  0.665241\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "softmax(xs) = exp.(xs) ./ sum(exp.(xs))\n",
       "```\n",
       "\n",
       "[Softmax](https://en.wikipedia.org/wiki/Softmax_function) takes log-probabilities (any real vector) and returns a probability distribution that sums to 1.\n",
       "\n",
       "If given a matrix it will treat it as a batch of vectors, with each column independent.\n",
       "\n",
       "```\n",
       "julia> softmax([1,2,3.])\n",
       "3-element Array{Float64,1}:\n",
       "  0.0900306\n",
       "  0.244728\n",
       "  0.665241\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  softmax(xs) = exp.(xs) ./ sum(exp.(xs))\u001b[39m\n",
       "\n",
       "  Softmax (https://en.wikipedia.org/wiki/Softmax_function) takes\n",
       "  log-probabilities (any real vector) and returns a probability distribution\n",
       "  that sums to 1.\n",
       "\n",
       "  If given a matrix it will treat it as a batch of vectors, with each column\n",
       "  independent.\n",
       "\n",
       "\u001b[36m  julia> softmax([1,2,3.])\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    0.0900306\u001b[39m\n",
       "\u001b[36m    0.244728\u001b[39m\n",
       "\u001b[36m    0.665241\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(4, 3), NNlib.softmax)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "# 4 features input (measurements of the iris flowers).\n",
    "# 3 classes output\n",
    "model = Chain(\n",
    "  Dense(4, 3),\n",
    "  softmax\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not all functions have documentation, e.g. crossentropy and onecold below.\n",
    "\n",
    "loss(x, y) = crossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* onecold converts a 2d array of probabilities into integers\n",
    "\n",
    "```julia\n",
    "julia> A = [.1 .7 1.; .9 .3 0]\n",
    "2×3 Array{Float64,2}:\n",
    " 0.1  0.7  1.0\n",
    " 0.9  0.3  0.0\n",
    "\n",
    "julia> onecold(A)\n",
    "3-element Array{Int64,1}:\n",
    " 2\n",
    " 1\n",
    " 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mD\u001b[22m AM\u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mG\u001b[22mra\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1mS\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m Un\u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m un\u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mmoi\u001b[0m\u001b[1md\u001b[22m i\u001b[0m\u001b[1ms\u001b[22mset\u001b[0m\u001b[1mg\u001b[22mi\u001b[0m\u001b[1md\u001b[22m log\u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mmoi\u001b[0m\u001b[1md\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "SGD(params, η = 0.1; decay = 0)\n",
       "\\end{verbatim}\n",
       "Classic gradient descent optimiser with learning rate \\texttt{η}. For each parameter \\texttt{p} and its gradient \\texttt{δp}, this runs \\texttt{p -= η*δp}.\n",
       "\n",
       "Supports inverse decaying learning rate if the \\texttt{decay} argument is provided.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "SGD(params, η = 0.1; decay = 0)\n",
       "```\n",
       "\n",
       "Classic gradient descent optimiser with learning rate `η`. For each parameter `p` and its gradient `δp`, this runs `p -= η*δp`.\n",
       "\n",
       "Supports inverse decaying learning rate if the `decay` argument is provided.\n"
      ],
      "text/plain": [
       "\u001b[36m  SGD(params, η = 0.1; decay = 0)\u001b[39m\n",
       "\n",
       "  Classic gradient descent optimiser with learning rate \u001b[36mη\u001b[39m. For each parameter\n",
       "  \u001b[36mp\u001b[39m and its gradient \u001b[36mδp\u001b[39m, this runs \u001b[36mp -= η*δp\u001b[39m.\n",
       "\n",
       "  Supports inverse decaying learning rate if the \u001b[36mdecay\u001b[39m argument is provided."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#43 (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = SGD(params(model), learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-element Array{Any,1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies  = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "* train the model.\n",
    "* test accuracy may be greater than training accuracy.  \n",
    "* Probably because the training and test set sizes are so small - only 150 examples total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m_accuracies y_\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m X_\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m y_\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m_onehot \u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mi\u001b[22mli\u001b[0m\u001b[1mn\u001b[22mg_ones\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "train!(loss, data, opt)\n",
       "\\end{verbatim}\n",
       "For each datapoint \\texttt{d} in \\texttt{data} computes the gradient of \\texttt{loss(d...)} through backpropagation and calls the optimizer \\texttt{opt}.\n",
       "\n",
       "Takes a callback as keyword argument \\texttt{cb}. For example, this will print \"training\" every 10 seconds:\n",
       "\n",
       "\\begin{verbatim}\n",
       "Flux.train!(loss, data, opt,\n",
       "            cb = throttle(() -> println(\"training\"), 10))\n",
       "\\end{verbatim}\n",
       "The callback can return \\texttt{:stop} to interrupt the training loop.\n",
       "\n",
       "Multiple optimisers and callbacks can be passed to \\texttt{opt} and \\texttt{cb} as arrays.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "train!(loss, data, opt)\n",
       "```\n",
       "\n",
       "For each datapoint `d` in `data` computes the gradient of `loss(d...)` through backpropagation and calls the optimizer `opt`.\n",
       "\n",
       "Takes a callback as keyword argument `cb`. For example, this will print \"training\" every 10 seconds:\n",
       "\n",
       "```julia\n",
       "Flux.train!(loss, data, opt,\n",
       "            cb = throttle(() -> println(\"training\"), 10))\n",
       "```\n",
       "\n",
       "The callback can return `:stop` to interrupt the training loop.\n",
       "\n",
       "Multiple optimisers and callbacks can be passed to `opt` and `cb` as arrays.\n"
      ],
      "text/plain": [
       "\u001b[36m  train!(loss, data, opt)\u001b[39m\n",
       "\n",
       "  For each datapoint \u001b[36md\u001b[39m in \u001b[36mdata\u001b[39m computes the gradient of \u001b[36mloss(d...)\u001b[39m through\n",
       "  backpropagation and calls the optimizer \u001b[36mopt\u001b[39m.\n",
       "\n",
       "  Takes a callback as keyword argument \u001b[36mcb\u001b[39m. For example, this will print\n",
       "  \"training\" every 10 seconds:\n",
       "\n",
       "\u001b[36m  Flux.train!(loss, data, opt,\u001b[39m\n",
       "\u001b[36m              cb = throttle(() -> println(\"training\"), 10))\u001b[39m\n",
       "\n",
       "  The callback can return \u001b[36m:stop\u001b[39m to interrupt the training loop.\n",
       "\n",
       "  Multiple optimisers and callbacks can be passed to \u001b[36mopt\u001b[39m and \u001b[36mcb\u001b[39m as arrays."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip0900\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2000\" height=\"2000\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0901\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip0901)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0902\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip0901)\" points=\"\n",
       "251.149,1440.48 2321.26,1440.48 2321.26,47.2441 251.149,47.2441 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0903\">\n",
       "    <rect x=\"251\" y=\"47\" width=\"2071\" height=\"1394\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  276.636,1440.48 276.636,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  607.642,1440.48 607.642,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  938.648,1440.48 938.648,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1269.65,1440.48 1269.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1600.66,1440.48 1600.66,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1931.67,1440.48 1931.67,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2262.67,1440.48 2262.67,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  251.149,1221.82 2321.26,1221.82 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  251.149,923.096 2321.26,923.096 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  251.149,624.375 2321.26,624.375 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  251.149,325.653 2321.26,325.653 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.149,1440.48 2321.26,1440.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.149,1440.48 251.149,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.636,1440.48 276.636,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  607.642,1440.48 607.642,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  938.648,1440.48 938.648,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1269.65,1440.48 1269.65,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1600.66,1440.48 1600.66,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1931.67,1440.48 1931.67,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2262.67,1440.48 2262.67,1419.58 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.149,1221.82 282.2,1221.82 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.149,923.096 282.2,923.096 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.149,624.375 282.2,624.375 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.149,325.653 282.2,325.653 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 276.636, 1494.48)\" x=\"276.636\" y=\"1494.48\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 607.642, 1494.48)\" x=\"607.642\" y=\"1494.48\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 938.648, 1494.48)\" x=\"938.648\" y=\"1494.48\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1269.65, 1494.48)\" x=\"1269.65\" y=\"1494.48\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1600.66, 1494.48)\" x=\"1600.66\" y=\"1494.48\">40</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1931.67, 1494.48)\" x=\"1931.67\" y=\"1494.48\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2262.67, 1494.48)\" x=\"2262.67\" y=\"1494.48\">60</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 227.149, 1239.32)\" x=\"227.149\" y=\"1239.32\">0.75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 227.149, 940.596)\" x=\"227.149\" y=\"940.596\">0.80</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 227.149, 641.875)\" x=\"227.149\" y=\"641.875\">0.85</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 227.149, 343.153)\" x=\"227.149\" y=\"343.153\">0.90</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1286.2, 1590.4)\" x=\"1286.2\" y=\"1590.4\">epoch</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 57.6, 743.863)\" x=\"57.6\" y=\"743.863\">% correct</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  309.737,1221.82 342.837,982.841 375.938,923.096 409.038,923.096 442.139,863.352 475.24,982.841 508.34,923.096 541.441,863.352 574.541,923.096 607.642,923.096 \n",
       "  640.743,982.841 673.843,923.096 706.944,923.096 740.044,923.096 773.145,923.096 806.246,923.096 839.346,863.352 872.447,803.608 905.547,743.863 938.648,743.863 \n",
       "  971.749,743.863 1004.85,743.863 1037.95,743.863 1071.05,743.863 1104.15,743.863 1137.25,743.863 1170.35,743.863 1203.45,743.863 1236.55,743.863 1269.65,743.863 \n",
       "  1302.75,743.863 1335.86,743.863 1368.96,743.863 1402.06,743.863 1435.16,684.119 1468.26,684.119 1501.36,684.119 1534.46,684.119 1567.56,684.119 1600.66,684.119 \n",
       "  1633.76,684.119 1666.86,684.119 1699.96,684.119 1733.06,684.119 1766.16,684.119 1799.26,684.119 1832.36,684.119 1865.46,684.119 1898.57,684.119 1931.67,684.119 \n",
       "  1964.77,684.119 1997.87,684.119 2030.97,684.119 2064.07,684.119 2097.17,684.119 2130.27,684.119 2163.37,684.119 2196.47,684.119 2229.57,684.119 2262.67,684.119 \n",
       "  \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0903)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  309.737,1401.05 342.837,1401.05 375.938,1401.05 409.038,1042.59 442.139,1042.59 475.24,923.096 508.34,923.096 541.441,803.608 574.541,684.119 607.642,684.119 \n",
       "  640.743,684.119 673.843,684.119 706.944,684.119 740.044,803.608 773.145,803.608 806.246,684.119 839.346,684.119 872.447,684.119 905.547,684.119 938.648,684.119 \n",
       "  971.749,684.119 1004.85,684.119 1037.95,684.119 1071.05,564.63 1104.15,564.63 1137.25,564.63 1170.35,564.63 1203.45,564.63 1236.55,445.142 1269.65,445.142 \n",
       "  1302.75,325.653 1335.86,206.164 1368.96,206.164 1402.06,206.164 1435.16,206.164 1468.26,206.164 1501.36,206.164 1534.46,206.164 1567.56,206.164 1600.66,206.164 \n",
       "  1633.76,206.164 1666.86,206.164 1699.96,206.164 1733.06,206.164 1766.16,206.164 1799.26,206.164 1832.36,206.164 1865.46,206.164 1898.57,206.164 1931.67,206.164 \n",
       "  1964.77,206.164 1997.87,86.6754 2030.97,86.6754 2064.07,86.6754 2097.17,86.6754 2130.27,86.6754 2163.37,86.6754 2196.47,86.6754 2229.57,86.6754 2262.67,86.6754 \n",
       "  \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip0901)\" points=\"\n",
       "1645.47,1296.48 2249.26,1296.48 2249.26,1115.04 1645.47,1115.04 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1645.47,1296.48 2249.26,1296.48 2249.26,1115.04 1645.47,1115.04 1645.47,1296.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1669.47,1175.52 1813.47,1175.52 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1837.47, 1193.02)\" x=\"1837.47\" y=\"1193.02\">training accuracy</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip0901)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1669.47,1236 1813.47,1236 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip0901)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1837.47, 1253.5)\" x=\"1837.47\" y=\"1253.5\">test accuracy</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in 1:60\n",
    "    push!(losses, data(loss(X_train, y_train_onehot)))\n",
    "    push!(train_accuracies, accuracy(X_train, y_train_onehot))\n",
    "    push!(test_accuracies, accuracy(X_test, y_test_onehot))\n",
    "\n",
    "    train!(loss, [(X_train, y_train_onehot)], optimizer)\n",
    "end\n",
    "\n",
    "\n",
    "plot(train_accuracies, label=\"training accuracy\", legend=:bottomright, xlabel=\"epoch\", ylabel=\"% correct\")\n",
    "plot!(test_accuracies, label=\"test accuracy\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
